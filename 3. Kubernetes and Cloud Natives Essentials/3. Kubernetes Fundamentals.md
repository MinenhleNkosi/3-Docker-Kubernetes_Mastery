# 0. Intro
ğŸ§  **Kubernetes Architecture**

## ğŸš€ Why Kubernetes Uses Clusters?
Kubernetes isnâ€™t meant to run on just one machine. Itâ€™s designed for **scale** â€” just like at Google, where **billions of containers** are started every week!

So instead of one big server, Kubernetes runs across many machines working **together**. This group of machines is called a **cluster**.

ğŸ“ˆ Kubernetes can:

* Scale to **thousands of servers**.

* Run **across data centers** or even **cloud regions**.

* Handle **huge workloads** with ease.

ğŸ§© Two Types of **Nodes**
Kubernetes clusters are made of two types of nodes:

**ğŸ§  1. Control Plane Node(s)**

These are the brains of the cluster ğŸ§¬

They:

* ğŸ§‘â€ğŸ”§ Manage deployments

* ğŸ“¦ Schedule containers

* ğŸ› ï¸ Detect and fix issues (self-healing)

* ğŸ” Track the overall system state

**Think of this like a manager giving instructions to workers**.

**ğŸ§° 2. Worker Nodes**

These are the **hands** of the cluster ğŸ™Œ

They:

* ğŸƒ Actually **run your containers**.

* ğŸ”§ Do whatever the **control plane** tells them.

* ğŸ§± Form the foundation of your **application infrastructure**.

## ğŸ”§ Behind the Scenes: Services on Each Node
Just like `microservices` in your own app, `Kubernetes` itself is made of small internal services that each have specific jobs:

* On the **control plane**, services like the API server, scheduler, and controller manager run.

* On the **worker nodes**, services like the container runtime and kubelet run to actually launch and monitor containers.

Each piece works together to create a self-healing, automated container platform. ğŸ› ï¸ğŸ¤–


<a ><br /><img src="https://app.eraser.io/workspace/Mh6RNld4rNvXQJmTbcJR/preview?elements=F79ZtffDjb-okAYJ9eTW-A&type=embed" /></a>

<br/>

# 1. Kubernetes Setup ğŸ§©
Setting up a Kubernetes cluster can be achieved with a lot of different methods. Creating a test "cluster" can be very easy with the right tools:

* [Minikube](https://minikube.sigs.k8s.io/docs/)
* [kind](https://kind.sigs.k8s.io/)
* [MicroK8s](https://microk8s.io/)

If you want to set up a production-grade cluster on your own hardware or virtual machines, you can choose one of the various installers:

* [kubeadm](https://kubernetes.io/docs/reference/setup-tools/kubeadm/)
* [kops](https://github.com/kubernetes/kops)
* [kubespray](https://github.com/kubernetes-sigs/kubespray)

A few vendors started packaging Kubernetes into a distribution and even offer commercial support:

* [Rancher](https://rancher.com/)
* [k3s](https://k3s.io/)
* [OpenShift](https://www.redhat.com/en/technologies/cloud-computing/openshift)
* [VMWare Tanzu](https://tanzu.vmware.com/tanzu)

The distributions often choose an opinionated approach and offer additional tools while using Kubernetes as the central piece of their framework.

If you donâ€™t want to install and manage it yourself, you can consume it from a cloud provider:

* [Amazon (EKS)](https://aws.amazon.com/eks/)
* [Google (GKE)](https://cloud.google.com/kubernetes-engine)
* [Microsoft (AKS)](https://azure.microsoft.com/en-us/services/kubernetes-service)
* [DigitalOcean (DOKS)](https://www.digitalocean.com/products/kubernetes/)

## Interactive Tutorial - Create a Cluster
You can learn how to set up your own Kubernetes cluster with Minikube in this [interactive tutorial](https://kubernetes.io/docs/tutorials/kubernetes-basics/create-cluster/cluster-intro/).

# 2. ğŸƒâ€â™‚ï¸ Running Containers on Kubernetes
## ğŸ–¥ï¸ Running Locally vs. In Kubernetes
When you run containers locally, you might use:

```bash
docker run nginx
```

ğŸ§  But in `Kubernetes`, it's not as direct!

* Instead of starting containers directly, `Kubernetes` uses **Pods** ğŸ§³

* A **Pod** is like a **wrapper around one or more containers**.

* It's the **smallest compute unit** in Kubernetes

ğŸ“¦ You **define a Pod**, and `Kubernetes` takes care of the rest â€” scheduling it, creating it, and running your container(s).

## âš™ï¸ How Kubernetes Runs Containers
When you create a Pod, Kubernetes goes through several layers to launch your container:

```nginx
You â†’ Pod â†’ Kubelet â†’ Container Runtime â†’ Container
```

Letâ€™s look at the **container runtimes** behind the scenes ğŸ‘‡

## ğŸ”¥ Popular Container Runtimes
### ğŸ“¦ containerd:

* ğŸ”§ Lightweight, fast, and reliable

* ğŸ† Most popular runtime today

* âœ… Used by major cloud providers

* âš¡ Runs containers efficiently for Kubernetes

### ğŸ› ï¸ CRI-O

* ğŸ§ª Created by Red Hat

* ğŸ§¬ Shares roots with Podman and Buildah

* ğŸ”’ Focuses on security and Kubernetes integration

### ğŸ³ Docker (Deprecated)

* â›µ The original and widely adopted runtime

* âŒ Removed from Kubernetes in version 1.24

* ğŸ“š Kubernetes blog explains the change in detail

Docker is still great for development, but `Kubernetes` now prefers **runtimes** that are **more focused** and **lightweight**.

## ğŸ” Security with Sandbox Runtimes
Sharing the host kernel can pose security risks ğŸ›¡ï¸
To improve container isolation, Kubernetes supports **sandboxed runtimes**:
### ğŸ” gVisor

* ğŸ—ï¸ Developed by Google

* ğŸ§± Inserts an **application kernel** between the container and host

### ğŸ›¡ï¸ Kata Containers

* ğŸ–¥ï¸ Lightweight **VM-like** isolation

* ğŸ§â€â™€ï¸ Feels like a container, behaves like a **virtual machine**

## ğŸ§  FYI:
| Runtime         | Key Feature                         | Notes                     |
| --------------- | ----------------------------------- | ------------------------- |
| containerd      | Fast, efficient, cloud-native       | Widely adopted            |
| CRI-O           | Kubernetes-focused, secure          | Built by Red Hat          |
| Docker          | Full-featured but deprecated in K8s | Still great for local dev |
| gVisor          | Kernel-level security               | Adds sandboxing           |
| Kata Containers | VM-style isolation for containers   | Secure, yet lightweight   |

The diagram below is the Kubernetes Architecture:

<a ><br /><img src="https://app.eraser.io/workspace/Mh6RNld4rNvXQJmTbcJR/preview?elements=Kv9eb8Zv6fFH7AuMLz2Eug&type=embed" /></a>

# 3. ğŸŒ Networking
**ğŸ¤¯ Why Is Kubernetes Networking Hard?**

Kubernetes networking can seem complicated because:

* You have **lots of containers**.

* Spread across **lots of nodes**

* All trying to **talk to each other**!

Kubernetes breaks this problem into 4 main types of communication:

## ğŸ”„ Communication Types in Kubernetes
| Communication Type        | How It's Solved                                        |
| ------------------------- | ------------------------------------------------------ |
| ğŸ§± Container â¡ï¸ Container | âœ… Solved by the **Pod** concept                        |
| ğŸ“¦ Pod â¡ï¸ Pod             | âœ… Solved by an **overlay network**                     |
| ğŸ“¦ Pod â¡ï¸ ğŸ“¡ Service      | âœ… Managed by **kube-proxy** and **packet filter**      |
| ğŸŒ External â¡ï¸ ğŸ“¡ Service | âœ… Also managed by **kube-proxy** and **packet filter** |

## ğŸ“œ Kubernetes Network Requirements
To keep everything running smoothly, Kubernetes expects these rules to be followed:

* âœ… **All Pods can talk to all other Pods**, even across nodes

* âœ… **All Nodes can talk to all Pods**

* âŒ **No NAT (Network Address Translation)** â€” so IPs stay the same throughout

    These rules ensure consistent, predictable networking for every container ğŸ§ 

## ğŸ“¬ How Pods Get IP Addresses
Every Pod gets its **own IP address** ğŸ†”
â¡ï¸ No need to share ports or manually configure IPs
â¡ï¸ `Kubernetes` makes it all work out-of-the-box ğŸ‰

And for **DNS**, Kubernetes uses a built-in service:

* ğŸ“¦ `core-dns`

* ğŸ§­ Helps Pods discover Services by name (e.g., `my-service.default.svc.cluster.local`)

## ğŸ”’ Controlling Traffic: Network Policies
By default:
### ğŸ”“ All Pods can talk to all other Pods
But what if you want to lock things down? ğŸ›¡ï¸
Thatâ€™s where **Network Policies** come in:

* ğŸ‘®â€â™€ï¸ **Act like firewalls inside the cluster**.

* ğŸ§© Use **selectors** to match Pods by labels or namespaces.

* ğŸ”¢ Can define **IP ranges** using CIDRs.

```yaml
kind: NetworkPolicy
spec:
  podSelector:
    matchLabels:
      role: db
  ingress:
    - from:
        - podSelector:
            matchLabels:
              role: frontend
```

â¡ï¸ Only allow traffic from Pods labeled `role: frontend` to reach Pods labeled `role: db`.

âš ï¸ **Important**: Network Policies only work if your networking plugin supports them!
(Examples: Calico, Cilium, Weave)

## ğŸ§  FYI:

* Kubernetes **handles basic networking for you**.

* You get **IP-per-Pod** and **automatic DNS**.

* Use **Network Policies** to control traffic like a pro ğŸ”.

* But make sure your **CNI plugin** supports them.

<a href="https://app.eraser.io/workspace/Mh6RNld4rNvXQJmTbcJR?elements=kbaLhi7GlZajDaZFhg8RwQ">View on Eraser<br /><img src="https://app.eraser.io/workspace/Mh6RNld4rNvXQJmTbcJR/preview?elements=kbaLhi7GlZajDaZFhg8RwQ&type=embed" /></a>
