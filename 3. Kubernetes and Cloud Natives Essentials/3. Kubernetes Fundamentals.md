# 0. Intro
🧠 **Kubernetes Architecture**

## 🚀 Why Kubernetes Uses Clusters?
Kubernetes isn’t meant to run on just one machine. It’s designed for **scale** — just like at Google, where **billions of containers** are started every week!

So instead of one big server, Kubernetes runs across many machines working **together**. This group of machines is called a **cluster**.

📈 Kubernetes can:

* Scale to **thousands of servers**.

* Run **across data centers** or even **cloud regions**.

* Handle **huge workloads** with ease.

🧩 Two Types of **Nodes**
Kubernetes clusters are made of two types of nodes:

**🧠 1. Control Plane Node(s)**

These are the brains of the cluster 🧬

They:

* 🧑‍🔧 Manage deployments

* 📦 Schedule containers

* 🛠️ Detect and fix issues (self-healing)

* 🔁 Track the overall system state

**Think of this like a manager giving instructions to workers**.

**🧰 2. Worker Nodes**

These are the **hands** of the cluster 🙌

They:

* 🏃 Actually **run your containers**.

* 🔧 Do whatever the **control plane** tells them.

* 🧱 Form the foundation of your **application infrastructure**.

## 🔧 Behind the Scenes: Services on Each Node
Just like `microservices` in your own app, `Kubernetes` itself is made of small internal services that each have specific jobs:

* On the **control plane**, services like the API server, scheduler, and controller manager run.

* On the **worker nodes**, services like the container runtime and kubelet run to actually launch and monitor containers.

Each piece works together to create a self-healing, automated container platform. 🛠️🤖


<a ><br /><img src="https://app.eraser.io/workspace/Mh6RNld4rNvXQJmTbcJR/preview?elements=F79ZtffDjb-okAYJ9eTW-A&type=embed" /></a>

<br/>

# 1. Kubernetes Setup 🧩
Setting up a Kubernetes cluster can be achieved with a lot of different methods. Creating a test "cluster" can be very easy with the right tools:

* [Minikube](https://minikube.sigs.k8s.io/docs/)
* [kind](https://kind.sigs.k8s.io/)
* [MicroK8s](https://microk8s.io/)

If you want to set up a production-grade cluster on your own hardware or virtual machines, you can choose one of the various installers:

* [kubeadm](https://kubernetes.io/docs/reference/setup-tools/kubeadm/)
* [kops](https://github.com/kubernetes/kops)
* [kubespray](https://github.com/kubernetes-sigs/kubespray)

A few vendors started packaging Kubernetes into a distribution and even offer commercial support:

* [Rancher](https://rancher.com/)
* [k3s](https://k3s.io/)
* [OpenShift](https://www.redhat.com/en/technologies/cloud-computing/openshift)
* [VMWare Tanzu](https://tanzu.vmware.com/tanzu)

The distributions often choose an opinionated approach and offer additional tools while using Kubernetes as the central piece of their framework.

If you don’t want to install and manage it yourself, you can consume it from a cloud provider:

* [Amazon (EKS)](https://aws.amazon.com/eks/)
* [Google (GKE)](https://cloud.google.com/kubernetes-engine)
* [Microsoft (AKS)](https://azure.microsoft.com/en-us/services/kubernetes-service)
* [DigitalOcean (DOKS)](https://www.digitalocean.com/products/kubernetes/)

## Interactive Tutorial - Create a Cluster
You can learn how to set up your own Kubernetes cluster with Minikube in this [interactive tutorial](https://kubernetes.io/docs/tutorials/kubernetes-basics/create-cluster/cluster-intro/).

# 2. 🏃‍♂️ Running Containers on Kubernetes
## 🖥️ Running Locally vs. In Kubernetes
When you run containers locally, you might use:

```bash
docker run nginx
```

🧠 But in `Kubernetes`, it's not as direct!

* Instead of starting containers directly, `Kubernetes` uses **Pods** 🧳

* A **Pod** is like a **wrapper around one or more containers**.

* It's the **smallest compute unit** in Kubernetes

📦 You **define a Pod**, and `Kubernetes` takes care of the rest — scheduling it, creating it, and running your container(s).

## ⚙️ How Kubernetes Runs Containers
When you create a Pod, Kubernetes goes through several layers to launch your container:

```nginx
You → Pod → Kubelet → Container Runtime → Container
```

Let’s look at the **container runtimes** behind the scenes 👇

## 🔥 Popular Container Runtimes
### 📦 containerd:

* 🔧 Lightweight, fast, and reliable

* 🏆 Most popular runtime today

* ✅ Used by major cloud providers

* ⚡ Runs containers efficiently for Kubernetes

### 🛠️ CRI-O

* 🧪 Created by Red Hat

* 🧬 Shares roots with Podman and Buildah

* 🔒 Focuses on security and Kubernetes integration

### 🐳 Docker (Deprecated)

* ⛵ The original and widely adopted runtime

* ❌ Removed from Kubernetes in version 1.24

* 📚 Kubernetes blog explains the change in detail

Docker is still great for development, but `Kubernetes` now prefers **runtimes** that are **more focused** and **lightweight**.

## 🔐 Security with Sandbox Runtimes
Sharing the host kernel can pose security risks 🛡️
To improve container isolation, Kubernetes supports **sandboxed runtimes**:
### 🔐 gVisor

* 🏗️ Developed by Google

* 🧱 Inserts an **application kernel** between the container and host

### 🛡️ Kata Containers

* 🖥️ Lightweight **VM-like** isolation

* 🧍‍♀️ Feels like a container, behaves like a **virtual machine**

## 🧠 FYI:
| Runtime         | Key Feature                         | Notes                     |
| --------------- | ----------------------------------- | ------------------------- |
| containerd      | Fast, efficient, cloud-native       | Widely adopted            |
| CRI-O           | Kubernetes-focused, secure          | Built by Red Hat          |
| Docker          | Full-featured but deprecated in K8s | Still great for local dev |
| gVisor          | Kernel-level security               | Adds sandboxing           |
| Kata Containers | VM-style isolation for containers   | Secure, yet lightweight   |

The diagram below is the Kubernetes Architecture:

<a ><br /><img src="https://app.eraser.io/workspace/Mh6RNld4rNvXQJmTbcJR/preview?elements=Kv9eb8Zv6fFH7AuMLz2Eug&type=embed" /></a>

# 3. 🌐 Networking
**🤯 Why Is Kubernetes Networking Hard?**

Kubernetes networking can seem complicated because:

* You have **lots of containers**.

* Spread across **lots of nodes**

* All trying to **talk to each other**!

Kubernetes breaks this problem into 4 main types of communication:

## 🔄 Communication Types in Kubernetes
| Communication Type        | How It's Solved                                        |
| ------------------------- | ------------------------------------------------------ |
| 🧱 Container ➡️ Container | ✅ Solved by the **Pod** concept                        |
| 📦 Pod ➡️ Pod             | ✅ Solved by an **overlay network**                     |
| 📦 Pod ➡️ 📡 Service      | ✅ Managed by **kube-proxy** and **packet filter**      |
| 🌍 External ➡️ 📡 Service | ✅ Also managed by **kube-proxy** and **packet filter** |

## 📜 Kubernetes Network Requirements
To keep everything running smoothly, Kubernetes expects these rules to be followed:

* ✅ **All Pods can talk to all other Pods**, even across nodes

* ✅ **All Nodes can talk to all Pods**

* ❌ **No NAT (Network Address Translation)** — so IPs stay the same throughout

    These rules ensure consistent, predictable networking for every container 🧠

## 📬 How Pods Get IP Addresses
Every Pod gets its **own IP address** 🆔
➡️ No need to share ports or manually configure IPs
➡️ `Kubernetes` makes it all work out-of-the-box 🎉

And for **DNS**, Kubernetes uses a built-in service:

* 📦 `core-dns`

* 🧭 Helps Pods discover Services by name (e.g., `my-service.default.svc.cluster.local`)

## 🔒 Controlling Traffic: Network Policies
By default:
### 🔓 All Pods can talk to all other Pods
But what if you want to lock things down? 🛡️
That’s where **Network Policies** come in:

* 👮‍♀️ **Act like firewalls inside the cluster**.

* 🧩 Use **selectors** to match Pods by labels or namespaces.

* 🔢 Can define **IP ranges** using CIDRs.

```yaml
kind: NetworkPolicy
spec:
  podSelector:
    matchLabels:
      role: db
  ingress:
    - from:
        - podSelector:
            matchLabels:
              role: frontend
```

➡️ Only allow traffic from Pods labeled `role: frontend` to reach Pods labeled `role: db`.

⚠️ **Important**: Network Policies only work if your networking plugin supports them!
(Examples: Calico, Cilium, Weave)

## 🧠 FYI:

* Kubernetes **handles basic networking for you**.

* You get **IP-per-Pod** and **automatic DNS**.

* Use **Network Policies** to control traffic like a pro 🔐.

* But make sure your **CNI plugin** supports them.

<a href="https://app.eraser.io/workspace/Mh6RNld4rNvXQJmTbcJR?elements=kbaLhi7GlZajDaZFhg8RwQ">View on Eraser<br /><img src="https://app.eraser.io/workspace/Mh6RNld4rNvXQJmTbcJR/preview?elements=kbaLhi7GlZajDaZFhg8RwQ&type=embed" /></a>
