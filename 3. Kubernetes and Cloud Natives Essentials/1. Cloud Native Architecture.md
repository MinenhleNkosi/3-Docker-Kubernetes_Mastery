<a><br /><img src="https://app.eraser.io/workspace/hwW3sqsODYHncrevuWzL/preview?elements=qqbXHRvTBIY49NH1G75Fpw&type=embed" /></a>

<br/>

# 1. Cloud Native Architecture ğŸš€
The need to **develop**, **deploy** and **designing** applications has changed due to the rise of **cloud computing**.

There is a lot of on-demand services that are offered by **cloud providers**, to name a few: `virtual servers`, `networking`, `storage`, `databases`, etc. **Deploying** and **managing** these services is very convenient, either interactively, or by using application programming interfaces (**APIs**).
Here we will be learning all about the principles of **Modern Application Architecture** also known as the `Cloud Native Architecture`.

## ğŸ“˜ Cloud Native Architecture Fundamentals:
As I begin my journey into cloud-native technologies, Iâ€™m learning that the heart of **cloud native architecture** is about building software thatâ€™s:

    1. Cost-efficient ğŸ’° 

    2. Reliable ğŸ” 

    3. Faster to deliverâš¡ 

This isnâ€™t just about *tools* or *code* â€” itâ€™s a mix of **culture**, **technology**, and **architecture patterns** all working together.

## ğŸ” What Does "Cloud Native" Really Mean?:
Iâ€™ve come across a few different definitions, but hereâ€™s the one that really clicked for me â€” from the [Cloud Native Computing Foundation (CNCF)](https://www.cncf.io/):

```
Cloud native technologies empower organizations and individuals to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds... Containers, service meshes, microservices, immutable infrastructure, and declarative APIs exemplify this approach... ğŸŒ
```

In short: **itâ€™s about building resilient, observable, loosely coupled systems that are easier to manage and update** ğŸš€.

## ğŸ›ï¸ From Monoliths to Microservices:
Before cloud native, most applications followed a **monolithic architecture** â€” big, *self-contained* applications with everything *bundled together*: UI, shopping cart, payment processing, etc. Think of one massive E-Commerce app doing it all ğŸ‘ŸğŸ›’ğŸ’³ğŸ“¦.

While this was simple to get started, it came with major trade-offs:

* Hard to scale (Scaling the application up or down) âš–ï¸

* Hard to update quickly (Lack of version control) â³

* Tough to coordinate across teams ğŸ§ ğŸ”—
  
<a><br/><img src="https://app.eraser.io/workspace/hwW3sqsODYHncrevuWzL/preview?elements=9sbVj2Sig2-MfQibPGTM7Q&type=embed" /></a>


## ğŸ”„ Enter Cloud Native: Breaking Things Down:
With cloud native, the idea is to split the application into smaller, focused pieces, often called microservices ğŸ§©. Each microservice handles a specific function and can be:

* Deployed independently ğŸ¯

* Owned by different teams ğŸ‘¥

* Scaled on its own ğŸ’ª

So if a ton of users hit the checkout, I could just scale that one service instead of the whole app ğŸ’¡.

<a><br /><img src="https://app.eraser.io/workspace/hwW3sqsODYHncrevuWzL/preview?elements=HPc4NtLAd8qktJ1HL325Sg&type=embed" /></a>

This modular approach isnâ€™t just a trend â€” itâ€™s how modern applications meet the demands of **speed**, **scale**, and **reliability** in todayâ€™s cloud-driven world ğŸŒ.

<br/>

# 2. Cloud Native Architecture: Key Characteristics â˜ï¸ğŸ§©
As I dive deeper into cloud native architecture, Iâ€™m discovering the essential characteristics that make it **powerful**, **scalable**, and **modern**. Here's what sets it apart:

## ğŸ¤– High Level of Automation:
**Automation** is the backbone of cloud native systems. From **development** to **deployment**, nearly every step can (and should!) be automated using:

* ğŸ”§ Modern automation tools

* ğŸ” CI/CD pipelines (automated processes for building, testing, and deploying code)

* ğŸ’¾ Version control systems like `Git`


## This kind of setup allows for:
* âœ… Fast, frequent, and safe updates to production

* ğŸ§ª Minimal human error

* ğŸ”„ Easier disaster recovery (rebuilding the system becomes far less painful)


## â¤ï¸ Self-Healing Systems:
Failures happen â€” and thatâ€™s okay.

Cloud native apps are designed to recover automatically. Thanks to built-in:

* ğŸ§  Health checks

* â™»ï¸ Auto-restart features

...only the **affected services** need to restart, not the whole app. Since everythingâ€™s broken into smaller parts, one failure doesn't bring the whole thing down ğŸ‘.

## ğŸ“ˆ Scalable by Design:
Scaling means serving more users **without** performance loss. With cloud native apps, I can:

* ğŸš€ Launch multiple instances of a service

* âš™ï¸ Auto-scale based on metrics like CPU or memory

* ğŸ”„ Load balance traffic to keep things smooth

This ensures my services remain **responsive** â€” even under heavy load ğŸ’¡.

## ğŸ’µ Cost- and Resource-Efficient:
Cloud native isnâ€™t just fast â€” itâ€™s **smart** with costs too:

* â¬‡ï¸ Scale down during low traffic

* ğŸ“‰ Use pay-as-you-go pricing models

* ğŸ§  Optimize infrastructure usage with orchestration tools like Kubernetes, which packs workloads more efficiently

That means less waste and more savings ğŸ’¸.

## ğŸ”§ Easy to Maintain:
With a **microservices architecture**, each component of the app is:

* ğŸª¶ Lightweight

* ğŸ§ª Easier to test

* ğŸ“¦ Easier to deploy

* ğŸ‘¥ Easier to hand off to individual teams

This modularity makes updates and collaboration far simpler.

## ğŸ” Secure by Default:
Security isnâ€™t an afterthought â€” itâ€™s baked in:

* ğŸ›¡ï¸ Traditional models used to trust users inside a network

* ğŸš« But in cloud environments, zero trust is the new standard:

      Every user

      Every device

      Every process
  
        ...must authenticate, no exceptions.

This is crucial for environments where infrastructure is shared across **teams** or **customers**.

Understanding these principles is helping me see why cloud native is such a big deal â€” and how itâ€™s shaping the future of software architecture ğŸŒ.

<br/>

# 3. Autoscaling: Smart Scaling for Cloud Native Apps ğŸ“ˆâš™ï¸
One of the coolest things Iâ€™m learning about **cloud native** apps is **autoscaling** â€” the ability to automatically adjust computing resources based on demand. Here's what Iâ€™ve picked up:

## ğŸ” What Is Autoscaling?:
Autoscaling means my app can:

* ğŸš€ Scale up when traffic increases.

* ğŸ’¤ Scale down when traffic drops.

This is usually done by monitoring key metrics like:

* ğŸ§  CPU usage.

* ğŸ—‚ï¸ Memory consumption.

* ğŸ“Š Business-specific metrics (like number of active users or orders)


## â†”ï¸ Horizontal vs ğŸ”¼ Vertical Scaling:
To understand the two types of scaling, hereâ€™s a helpful metaphor ğŸ‹ï¸:

    Imagine trying to lift a heavy object:

        ğŸ’ª Vertical scaling is like building more muscle so you can lift it.

        ğŸ‘¥ Horizontal scaling is like calling your friends to help share the load.


## ğŸ” Horizontal Scaling:

* Adds more instances of your app or service.

* Often done by spinning up more containers, VMs, or even physical servers.

* The go-to method in cloud environments.

The below is an examples for an **E-Commerce application** with **vertical scaling**. The need for a vertical scaling is that there is a **large number** of users interacting with the application thus more products were bought. 

<a><br /><img src="https://app.eraser.io/workspace/PdEX5bJXiE6yVrjaLFCq/preview?elements=Oe5KrRdX9Wsr19SNsl0ASg&type=embed" /></a>

The solution was to:
* For `Infrastructure`, add more **Cloud VMs**, **App Auto-scaling** groups, **DB Auto-scaling** group, **Containers** to lacate resources per demand.
* For `Components`, adding more application servers to handle processes like **Order Processor**, **Session Management**, **Payment Handler**.
* For `Functionalities`, **User authentication** and **Profile management**. **Cloud-based virtual machines or containers** and order fulfillment.

## ğŸ”¼ Vertical Scaling

* Increases power of existing resources (more CPU/RAM).

* Good for quick boosts, but limited by hardware capacity.

* Less flexible in the long term.

The below is an examples for an **E-Commerce application** with **vertical scaling**. The need for a vertical scaling is that there is a **large number** of users interacting with the application thus more products were bought. 

<a><br /><img src="https://app.eraser.io/workspace/PdEX5bJXiE6yVrjaLFCq/preview?elements=6rhH7acTPxy9YXJwWMuZmA&type=embed" /></a>

The solution was to:
* Add more `Hardware` upgrade to the infrastructure (Increasing the RAM for smooth buying process of products).
* For `Components`, add application server to improve performance and user management and also payment process.
* For `Functionalities`, **User Authentication** and **Profile Management**. **Payment processing** and order fulfillment.

## âš™ï¸ How Autoscaling Works:
To configure autoscaling, you typically set:

* ğŸ”¢ Min/Max instance limits

* ğŸ“ Scaling rules (e.g., if CPU > 70% for 5 mins, scale up)

But getting this right isnâ€™t magic â€” it takes:

* ğŸ§ª Load testing

* ğŸ” Monitoring real-time performance

* âš–ï¸ Tuning your load balancing strategy


## â˜ï¸ Why the Cloud Makes This Easier:
Cloud platforms are perfect for autoscaling because they:

* ğŸ§  Can scale dynamically in seconds

* ğŸ’µ Use pay-as-you-go pricing

* ğŸ§Š Even support scaling to zero when services arenâ€™t needed

This means I donâ€™t have to overpay for idle resources and can respond instantly to changing demand. ğŸ’¥

## ğŸ§± Even Without Automationâ€¦:
Even if Iâ€™m not fully automating scaling (yet), having the ability to manually scale up/down still boosts:

* ğŸ›¡ï¸ Availability

* ğŸ”„ Resilience

* ğŸ‘¨â€ğŸ”§ Flexibility â€” even in traditional or hybrid setups

Learning how to scale **efficiently** is helping me see how cloud native systems stay **responsive**, **cost-effective**, and **resilient** â€” even under pressure ğŸ’ª.

<br/>

# 4. Understanding Serverless Computing ğŸ§ 
Despite the name, **serverless** doesnâ€™t mean there are no servers â€” it just means I donâ€™t have to manage them! ğŸ™Œ

In traditional cloud setups, Iâ€™d need to configure things like:

* ğŸŒ Networks.

* ğŸ–¥ï¸ Virtual Machines.

* âš™ï¸ Operating systems.

* âš–ï¸ Load balancers.

With **serverless**, I can skip all that and just deploy my application code â€” the cloud provider takes care of the rest. ğŸ‰

## ğŸ” Function as a Service (FaaS)
A common type of serverless is **FaaS**. Hereâ€™s how it works:

* I upload my code (as a .zip file or container image)

* The cloud provider automatically picks the right environment

* It scales based on events (like incoming requests)

* I only pay for whatâ€™s used, often billed per event, not per hour â±ï¸ğŸ’¸

Major cloud providers all offer some form of serverless or **FaaS**.

## ğŸš€ Why Use Serverless?
âœ… Super fast deployments.
âœ… Excellent for testing & sandbox environments.
âœ… Perfect for small, stateless apps like:

* Event handling.

* Batch jobs.

* Business logic.

* Scheduled tasks.

It doesnâ€™t replace containers or VMs completely â€” but itâ€™s a powerful addition to my cloud toolkit ğŸ”§.

## ğŸ§± Serverless on Kubernetes: Knative
For private clouds or on-prem environments, tools like `Knative` bring serverless features into `Kubernetes`, enabling:

* âš™ï¸ Fast deployment.

* ğŸ¯ Event-based execution.

* ğŸ“¦ Container support.

However, while this simplifies development, it may **increase** platform complexity for operators.

## ğŸŒ Tackling Vendor Lock-In with CloudEvents
One challenge with serverless: many proprietary systems = hard to move between clouds ğŸ˜¬

#### Enter: CloudEvents ğŸŒ©ï¸
A standard for structuring event data across platforms.

* ğŸ§¾ Makes events consistent across tools.

* ğŸ” Helps trigger serverless functions in a portable way.

* ğŸ› ï¸ Maintained by the `Cloud Native Computing Foundation` (CNCF).

The more widely adopted CloudEvents becomes, the easier it is to build portable, event-driven apps ğŸ§©.

## ğŸ“Œ Key Takeaways
* **Serverless** = focus on code, not infrastructure.

* **FaaS** scales automatically based on events.

* Great for **small**, **stateless**, **fast-executing** tasks.

* Tools like `Knative` bring serverless to `Kubernetes`.

* `CloudEvents` aims to simplify event handling across ecosystems.

<a><br/><img src="https://app.eraser.io/workspace/PdEX5bJXiE6yVrjaLFCq/preview?elements=5Z7KmXY9E9HA97AC_Cyi3g&type=embed" /></a>

<br/>

# 5. Open Standards in Cloud Native Tech ğŸ› ï¸
One of the biggest strengths of cloud native technologies is their deep connection to **open source** ğŸŒ. This openness:

* ğŸ‘¥ Encourages community collaboration

* ğŸ”„ Makes it easier to adopt shared industry-wide standards

* ğŸš« Helps avoid vendor lock-in by promoting compatibility across platforms

Many commercial products and cloud platforms even build directly on these open standards.

## ğŸ“¦ The Challenge: Packaging Software:
Modern apps often have lots of **dependencies** â€” from `operating systems` to `runtimes`. So how do we consistently package and deliver them?

ğŸ‘‰ Enter: **Containers** ğŸ³
Theyâ€™ve become the *de facto* standard for **packaging** and **distributing** software.

## ğŸ§± Open Container Initiative (OCI)
Although many people associate containers with `Docker`, the container ecosystem has moved toward **open**, **vendor-neutral** standards â€” thanks to the `Open Container Initiative` (OCI), founded under the `Linux Foundation` ğŸ§.

## OCI defines how containers should be built, run, and shared:
ğŸ“œ **image-spec**:

* Defines how to build and package container images

* Ensures consistent and portable container images across tools

âš™ï¸ **runtime-spec**:

* Describes how containers execute and behave

* Covers the config, execution environment, and lifecycle

ğŸ“¦ **distribution-spec**

* A newer spec that standardizes how container images and content are shared/distributed (e.g., via registries like Docker Hub)

## ğŸŒ Why Open Standards Matter?

* ğŸ”“ Promote interoperability.

* â™»ï¸ Enable reuse across platforms and tools.

* ğŸ§© Help build a truly cloud-native ecosystem that doesnâ€™t rely on any single vendor.

Using and contributing to **open standards** helps ensure that my cloud native skills and tools remain **relevant** and **portable** â€” wherever I go ğŸš€.

<br/>

# 6. Cloud Native Roles & Site Reliability Engineering (SRE) ğŸ‘¥
As cloud native technologies continue to evolve, so do the **jobs** that support them. Traditional IT roles like **system admin**, **network engineer**, or **test manager still** matter â€” but in todayâ€™s world, responsibilities are **often shared** and cross-functional ğŸ§©.

## Cloud Native Roles Explained â˜ï¸
Hereâ€™s a breakdown of the key roles Iâ€™m seeing in cloud native environments:
### ğŸ—ï¸ Cloud Architect

* Designs the **overall cloud strategy**.

* Focuses on **security**, **scalability**, and **deployment**.

* Bridges the gap between business goals and tech infrastructure.

### ğŸ” DevOps Engineer

* Not just a mix of developer and sysadmin!

* Builds **tools** and **processes** to integrate **development** and **operations**.

* Works across the entire software lifecycle: **coding** â†’ **testing** â†’ **deploying** â†’ **monitoring**.

### ğŸ›¡ï¸ Security Engineer

* Handles **security risks** in a cloud environment.

* Manages **cloud-native security challenges** like identity, access control, and container vulnerabilities.

* Security is no longer siloed â€” itâ€™s a **team-wide responsibility**.

### ğŸ” DevSecOps Engineer

* Combines **DevOps** and **Security**.

* Embeds security into every phase of the development cycle.

* Helps create a culture of â€œ**security by default**â€.

### ğŸ“Š Data Engineer

* Works with **big data**: collection, storage, processing.

* Builds infrastructure for **data pipelines**, **ETL jobs**, and **analytics**.

* Supports data-driven decision making.

### ğŸŒ Full-Stack Developer

* A **generalist** who handles both **frontend** and **backend**.

    Often knows enough about **infrastructure** to deploy or troubleshoot in production.

    Ideal for teams that need flexibility and speed.

### ğŸ› ï¸ Site Reliability Engineer (SRE): The Glue Between Dev & Ops
What Is SRE?
* Born at **Google in 2003**, the SRE role focuses on **reliability**, **scalability**, and **automation**.

* Think: "**Operations through software engineering**".

SREs use code to solve operational problems and aim to keep systems up, fast, and reliable ğŸ”§âš™ï¸

## ğŸ“ SRE Core Metrics
SREs rely on three key concepts to measure reliability:
### ğŸ¯ Service Level Objectives (SLOs):
* Target performance goals â€” e.g., â€œrespond to 95% of requests in under 100msâ€

### ğŸ“ˆ Service Level Indicators (SLIs):
* Actual measured values â€” e.g., â€œaverage response time is 87msâ€

#### ğŸ“„ Service Level Agreements (SLAs):
* Contracts with users about SLOs â€” and what happens if theyâ€™re missed (ğŸ’¸ fines, credits, etc.)

## âŒ What Is an Error Budget?
* An **error budget** defines how much failure is acceptable.

For example:
If my SLO is 99.9% uptime, Iâ€™m allowed **43 minutes of downtime/month**.

If the system exceeds that limit:

* ğŸš« Pause new deployments.

* ğŸ§ª Investigate stability issues.

* ğŸ” Re-prioritize operational work.

<br />

# 7. Community & Governance in Cloud Native ğŸ¤
One of the most powerful aspects of cloud native technologies is the **open source** community that **builds** and **maintains** them â€” and at the center of that is the **Cloud Native Computing Foundation** (CNCF) ğŸŒ.

## ğŸ§± CNCF: Building Blocks of Cloud Native
The CNCF is home to many of the most important **open source** projects in cloud computing â€” like `Kubernetes`, `Prometheus`, and `Envoy`.

Projects go through three stages of maturity:

* ğŸ§ª **Sandbox** â€“ Early-stage ideas and experimentation

* ğŸŒ± **Incubation** â€“ Gaining traction and community support

* ğŸ“ **Graduation** â€“ Proven stability, widespread adoption, and strong governance

The CNCF supports these projects at every stage â€” helping with things like *visibility*, *best practices*, and *promotion* on the CNCF Landscape ğŸŒ.

## âš–ï¸ Technical Oversight Committee (TOC)
The TOC helps guide the technical direction of CNCF projects. Its responsibilities include:

* ğŸ§­ Defining the technical vision

* âœ… Approving new projects

* ğŸ—£ï¸ Accepting input from the End User Community

* ğŸ“ Promoting consistent practices across CNCF projects

## ğŸ§‘â€ğŸ¤â€ğŸ§‘ Community-Driven, Not Top-Down
Hereâ€™s what makes cloud native governance unique:

    Projects are self-governing and community-owned ğŸ‘¥

    CNCF uses a model of â€œminimum viable governanceâ€ â€” just enough structure to guide, but not control

    Rules around:

        ğŸ“¦ Releasing software

        ğŸ‘€ Code review processes

        ğŸ‘¥ User and working group formation

In contrast to traditional, top-down corporate governance, cloud native projects thrive on voluntary participation, transparency, and shared ownership.

## ğŸ› ï¸ Why Governance Matters
Strong, lightweight governance ensures:

* âš–ï¸ Fair decision-making

* ğŸš€ Sustainable project growth

* ğŸ”„ Continuity even when contributors change

* ğŸ” Trust from users and adopters

In open source, freedom comes with responsibility â€” contributors and maintainers agree to follow shared rules to keep the ecosystem healthy and inclusive ğŸ’¡.
