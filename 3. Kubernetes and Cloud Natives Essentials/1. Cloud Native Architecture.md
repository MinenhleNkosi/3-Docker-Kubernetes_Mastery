<a><br /><img src="https://app.eraser.io/workspace/hwW3sqsODYHncrevuWzL/preview?elements=qqbXHRvTBIY49NH1G75Fpw&type=embed" /></a>

<br/>

# 1. Cloud Native Architecture 🚀
The need to **develop**, **deploy** and **designing** applications has changed due to the rise of **cloud computing**.

There is a lot of on-demand services that are offered by **cloud providers**, to name a few: `virtual servers`, `networking`, `storage`, `databases`, etc. **Deploying** and **managing** these services is very convenient, either interactively, or by using application programming interfaces (**APIs**).
Here we will be learning all about the principles of **Modern Application Architecture** also known as the `Cloud Native Architecture`.

## 📘 Cloud Native Architecture Fundamentals:
As I begin my journey into cloud-native technologies, I’m learning that the heart of **cloud native architecture** is about building software that’s:

    1. Cost-efficient 💰 

    2. Reliable 🔁 

    3. Faster to deliver⚡ 

This isn’t just about *tools* or *code* — it’s a mix of **culture**, **technology**, and **architecture patterns** all working together.

## 🔍 What Does "Cloud Native" Really Mean?:
I’ve come across a few different definitions, but here’s the one that really clicked for me — from the [Cloud Native Computing Foundation (CNCF)](https://www.cncf.io/):

```
Cloud native technologies empower organizations and individuals to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds... Containers, service meshes, microservices, immutable infrastructure, and declarative APIs exemplify this approach... 🌐
```

In short: **it’s about building resilient, observable, loosely coupled systems that are easier to manage and update** 🚀.

## 🏛️ From Monoliths to Microservices:
Before cloud native, most applications followed a **monolithic architecture** — big, *self-contained* applications with everything *bundled together*: UI, shopping cart, payment processing, etc. Think of one massive E-Commerce app doing it all 👟🛒💳📦.

While this was simple to get started, it came with major trade-offs:

* Hard to scale (Scaling the application up or down) ⚖️

* Hard to update quickly (Lack of version control) ⏳

* Tough to coordinate across teams 🧠🔗
  
<a><br/><img src="https://app.eraser.io/workspace/hwW3sqsODYHncrevuWzL/preview?elements=9sbVj2Sig2-MfQibPGTM7Q&type=embed" /></a>


## 🔄 Enter Cloud Native: Breaking Things Down:
With cloud native, the idea is to split the application into smaller, focused pieces, often called microservices 🧩. Each microservice handles a specific function and can be:

* Deployed independently 🎯

* Owned by different teams 👥

* Scaled on its own 💪

So if a ton of users hit the checkout, I could just scale that one service instead of the whole app 💡.

<a><br /><img src="https://app.eraser.io/workspace/hwW3sqsODYHncrevuWzL/preview?elements=HPc4NtLAd8qktJ1HL325Sg&type=embed" /></a>

This modular approach isn’t just a trend — it’s how modern applications meet the demands of **speed**, **scale**, and **reliability** in today’s cloud-driven world 🌍.

<br/>

# 2. Cloud Native Architecture: Key Characteristics ☁️🧩
As I dive deeper into cloud native architecture, I’m discovering the essential characteristics that make it **powerful**, **scalable**, and **modern**. Here's what sets it apart:

## 🤖 High Level of Automation:
**Automation** is the backbone of cloud native systems. From **development** to **deployment**, nearly every step can (and should!) be automated using:

* 🔧 Modern automation tools

* 🔁 CI/CD pipelines (automated processes for building, testing, and deploying code)

* 💾 Version control systems like `Git`


## This kind of setup allows for:
* ✅ Fast, frequent, and safe updates to production

* 🧪 Minimal human error

* 🔄 Easier disaster recovery (rebuilding the system becomes far less painful)


## ❤️ Self-Healing Systems:
Failures happen — and that’s okay.

Cloud native apps are designed to recover automatically. Thanks to built-in:

* 🧠 Health checks

* ♻️ Auto-restart features

...only the **affected services** need to restart, not the whole app. Since everything’s broken into smaller parts, one failure doesn't bring the whole thing down 👏.

## 📈 Scalable by Design:
Scaling means serving more users **without** performance loss. With cloud native apps, I can:

* 🚀 Launch multiple instances of a service

* ⚙️ Auto-scale based on metrics like CPU or memory

* 🔄 Load balance traffic to keep things smooth

This ensures my services remain **responsive** — even under heavy load 💡.

## 💵 Cost- and Resource-Efficient:
Cloud native isn’t just fast — it’s **smart** with costs too:

* ⬇️ Scale down during low traffic

* 📉 Use pay-as-you-go pricing models

* 🧠 Optimize infrastructure usage with orchestration tools like Kubernetes, which packs workloads more efficiently

That means less waste and more savings 💸.

## 🔧 Easy to Maintain:
With a **microservices architecture**, each component of the app is:

* 🪶 Lightweight

* 🧪 Easier to test

* 📦 Easier to deploy

* 👥 Easier to hand off to individual teams

This modularity makes updates and collaboration far simpler.

## 🔐 Secure by Default:
Security isn’t an afterthought — it’s baked in:

* 🛡️ Traditional models used to trust users inside a network

* 🚫 But in cloud environments, zero trust is the new standard:

      Every user

      Every device

      Every process
  
        ...must authenticate, no exceptions.

This is crucial for environments where infrastructure is shared across **teams** or **customers**.

Understanding these principles is helping me see why cloud native is such a big deal — and how it’s shaping the future of software architecture 🌍.

<br/>

# 3. Autoscaling: Smart Scaling for Cloud Native Apps 📈⚙️
One of the coolest things I’m learning about **cloud native** apps is **autoscaling** — the ability to automatically adjust computing resources based on demand. Here's what I’ve picked up:

## 🔁 What Is Autoscaling?:
Autoscaling means my app can:

* 🚀 Scale up when traffic increases.

* 💤 Scale down when traffic drops.

This is usually done by monitoring key metrics like:

* 🧠 CPU usage.

* 🗂️ Memory consumption.

* 📊 Business-specific metrics (like number of active users or orders)


## ↔️ Horizontal vs 🔼 Vertical Scaling:
To understand the two types of scaling, here’s a helpful metaphor 🏋️:

    Imagine trying to lift a heavy object:

        💪 Vertical scaling is like building more muscle so you can lift it.

        👥 Horizontal scaling is like calling your friends to help share the load.


## 🔁 Horizontal Scaling:

* Adds more instances of your app or service.

* Often done by spinning up more containers, VMs, or even physical servers.

* The go-to method in cloud environments.

The below is an examples for an **E-Commerce application** with **vertical scaling**. The need for a vertical scaling is that there is a **large number** of users interacting with the application thus more products were bought. 

<a><br /><img src="https://app.eraser.io/workspace/PdEX5bJXiE6yVrjaLFCq/preview?elements=Oe5KrRdX9Wsr19SNsl0ASg&type=embed" /></a>

The solution was to:
* For `Infrastructure`, add more **Cloud VMs**, **App Auto-scaling** groups, **DB Auto-scaling** group, **Containers** to lacate resources per demand.
* For `Components`, adding more application servers to handle processes like **Order Processor**, **Session Management**, **Payment Handler**.
* For `Functionalities`, **User authentication** and **Profile management**. **Cloud-based virtual machines or containers** and order fulfillment.

## 🔼 Vertical Scaling

* Increases power of existing resources (more CPU/RAM).

* Good for quick boosts, but limited by hardware capacity.

* Less flexible in the long term.

The below is an examples for an **E-Commerce application** with **vertical scaling**. The need for a vertical scaling is that there is a **large number** of users interacting with the application thus more products were bought. 

<a><br /><img src="https://app.eraser.io/workspace/PdEX5bJXiE6yVrjaLFCq/preview?elements=6rhH7acTPxy9YXJwWMuZmA&type=embed" /></a>

The solution was to:
* Add more `Hardware` upgrade to the infrastructure (Increasing the RAM for smooth buying process of products).
* For `Components`, add application server to improve performance and user management and also payment process.
* For `Functionalities`, **User Authentication** and **Profile Management**. **Payment processing** and order fulfillment.

## ⚙️ How Autoscaling Works:
To configure autoscaling, you typically set:

* 🔢 Min/Max instance limits

* 📏 Scaling rules (e.g., if CPU > 70% for 5 mins, scale up)

But getting this right isn’t magic — it takes:

* 🧪 Load testing

* 🔍 Monitoring real-time performance

* ⚖️ Tuning your load balancing strategy


## ☁️ Why the Cloud Makes This Easier:
Cloud platforms are perfect for autoscaling because they:

* 🧠 Can scale dynamically in seconds

* 💵 Use pay-as-you-go pricing

* 🧊 Even support scaling to zero when services aren’t needed

This means I don’t have to overpay for idle resources and can respond instantly to changing demand. 💥

## 🧱 Even Without Automation…:
Even if I’m not fully automating scaling (yet), having the ability to manually scale up/down still boosts:

* 🛡️ Availability

* 🔄 Resilience

* 👨‍🔧 Flexibility — even in traditional or hybrid setups

Learning how to scale **efficiently** is helping me see how cloud native systems stay **responsive**, **cost-effective**, and **resilient** — even under pressure 💪.

<br/>

# 4. Understanding Serverless Computing 🧠
Despite the name, **serverless** doesn’t mean there are no servers — it just means I don’t have to manage them! 🙌

In traditional cloud setups, I’d need to configure things like:

* 🌐 Networks.

* 🖥️ Virtual Machines.

* ⚙️ Operating systems.

* ⚖️ Load balancers.

With **serverless**, I can skip all that and just deploy my application code — the cloud provider takes care of the rest. 🎉

## 🔁 Function as a Service (FaaS)
A common type of serverless is **FaaS**. Here’s how it works:

* I upload my code (as a .zip file or container image)

* The cloud provider automatically picks the right environment

* It scales based on events (like incoming requests)

* I only pay for what’s used, often billed per event, not per hour ⏱️💸

Major cloud providers all offer some form of serverless or **FaaS**.

## 🚀 Why Use Serverless?
✅ Super fast deployments.
✅ Excellent for testing & sandbox environments.
✅ Perfect for small, stateless apps like:

* Event handling.

* Batch jobs.

* Business logic.

* Scheduled tasks.

It doesn’t replace containers or VMs completely — but it’s a powerful addition to my cloud toolkit 🔧.

## 🧱 Serverless on Kubernetes: Knative
For private clouds or on-prem environments, tools like `Knative` bring serverless features into `Kubernetes`, enabling:

* ⚙️ Fast deployment.

* 🎯 Event-based execution.

* 📦 Container support.

However, while this simplifies development, it may **increase** platform complexity for operators.

## 🌐 Tackling Vendor Lock-In with CloudEvents
One challenge with serverless: many proprietary systems = hard to move between clouds 😬

#### Enter: CloudEvents 🌩️
A standard for structuring event data across platforms.

* 🧾 Makes events consistent across tools.

* 🔁 Helps trigger serverless functions in a portable way.

* 🛠️ Maintained by the `Cloud Native Computing Foundation` (CNCF).

The more widely adopted CloudEvents becomes, the easier it is to build portable, event-driven apps 🧩.

## 📌 Key Takeaways
* **Serverless** = focus on code, not infrastructure.

* **FaaS** scales automatically based on events.

* Great for **small**, **stateless**, **fast-executing** tasks.

* Tools like `Knative` bring serverless to `Kubernetes`.

* `CloudEvents` aims to simplify event handling across ecosystems.

<a><br/><img src="https://app.eraser.io/workspace/PdEX5bJXiE6yVrjaLFCq/preview?elements=5Z7KmXY9E9HA97AC_Cyi3g&type=embed" /></a>

<br/>

# 5. Open Standards in Cloud Native Tech 🛠️
One of the biggest strengths of cloud native technologies is their deep connection to **open source** 🌐. This openness:

* 👥 Encourages community collaboration

* 🔄 Makes it easier to adopt shared industry-wide standards

* 🚫 Helps avoid vendor lock-in by promoting compatibility across platforms

Many commercial products and cloud platforms even build directly on these open standards.

## 📦 The Challenge: Packaging Software:
Modern apps often have lots of **dependencies** — from `operating systems` to `runtimes`. So how do we consistently package and deliver them?

👉 Enter: **Containers** 🐳
They’ve become the *de facto* standard for **packaging** and **distributing** software.

## 🧱 Open Container Initiative (OCI)
Although many people associate containers with `Docker`, the container ecosystem has moved toward **open**, **vendor-neutral** standards — thanks to the `Open Container Initiative` (OCI), founded under the `Linux Foundation` 🐧.

## OCI defines how containers should be built, run, and shared:
📜 **image-spec**:

* Defines how to build and package container images

* Ensures consistent and portable container images across tools

⚙️ **runtime-spec**:

* Describes how containers execute and behave

* Covers the config, execution environment, and lifecycle

📦 **distribution-spec**

* A newer spec that standardizes how container images and content are shared/distributed (e.g., via registries like Docker Hub)

## 🌍 Why Open Standards Matter?

* 🔓 Promote interoperability.

* ♻️ Enable reuse across platforms and tools.

* 🧩 Help build a truly cloud-native ecosystem that doesn’t rely on any single vendor.

Using and contributing to **open standards** helps ensure that my cloud native skills and tools remain **relevant** and **portable** — wherever I go 🚀.

<br/>

# 6. Cloud Native Roles & Site Reliability Engineering (SRE) 👥
As cloud native technologies continue to evolve, so do the **jobs** that support them. Traditional IT roles like **system admin**, **network engineer**, or **test manager still** matter — but in today’s world, responsibilities are **often shared** and cross-functional 🧩.

## Cloud Native Roles Explained ☁️
Here’s a breakdown of the key roles I’m seeing in cloud native environments:
### 🏗️ Cloud Architect

* Designs the **overall cloud strategy**.

* Focuses on **security**, **scalability**, and **deployment**.

* Bridges the gap between business goals and tech infrastructure.

### 🔁 DevOps Engineer

* Not just a mix of developer and sysadmin!

* Builds **tools** and **processes** to integrate **development** and **operations**.

* Works across the entire software lifecycle: **coding** → **testing** → **deploying** → **monitoring**.

### 🛡️ Security Engineer

* Handles **security risks** in a cloud environment.

* Manages **cloud-native security challenges** like identity, access control, and container vulnerabilities.

* Security is no longer siloed — it’s a **team-wide responsibility**.

### 🔐 DevSecOps Engineer

* Combines **DevOps** and **Security**.

* Embeds security into every phase of the development cycle.

* Helps create a culture of “**security by default**”.

### 📊 Data Engineer

* Works with **big data**: collection, storage, processing.

* Builds infrastructure for **data pipelines**, **ETL jobs**, and **analytics**.

* Supports data-driven decision making.

### 🌐 Full-Stack Developer

* A **generalist** who handles both **frontend** and **backend**.

    Often knows enough about **infrastructure** to deploy or troubleshoot in production.

    Ideal for teams that need flexibility and speed.

### 🛠️ Site Reliability Engineer (SRE): The Glue Between Dev & Ops
What Is SRE?
* Born at **Google in 2003**, the SRE role focuses on **reliability**, **scalability**, and **automation**.

* Think: "**Operations through software engineering**".

SREs use code to solve operational problems and aim to keep systems up, fast, and reliable 🔧⚙️

## 📏 SRE Core Metrics
SREs rely on three key concepts to measure reliability:
### 🎯 Service Level Objectives (SLOs):
* Target performance goals — e.g., “respond to 95% of requests in under 100ms”

### 📈 Service Level Indicators (SLIs):
* Actual measured values — e.g., “average response time is 87ms”

#### 📄 Service Level Agreements (SLAs):
* Contracts with users about SLOs — and what happens if they’re missed (💸 fines, credits, etc.)

## ❌ What Is an Error Budget?
* An **error budget** defines how much failure is acceptable.

For example:
If my SLO is 99.9% uptime, I’m allowed **43 minutes of downtime/month**.

If the system exceeds that limit:

* 🚫 Pause new deployments.

* 🧪 Investigate stability issues.

* 🔁 Re-prioritize operational work.

<br />

# 7. Community & Governance in Cloud Native 🤝
One of the most powerful aspects of cloud native technologies is the **open source** community that **builds** and **maintains** them — and at the center of that is the **Cloud Native Computing Foundation** (CNCF) 🌐.

## 🧱 CNCF: Building Blocks of Cloud Native
The CNCF is home to many of the most important **open source** projects in cloud computing — like `Kubernetes`, `Prometheus`, and `Envoy`.

Projects go through three stages of maturity:

* 🧪 **Sandbox** – Early-stage ideas and experimentation

* 🌱 **Incubation** – Gaining traction and community support

* 🎓 **Graduation** – Proven stability, widespread adoption, and strong governance

The CNCF supports these projects at every stage — helping with things like *visibility*, *best practices*, and *promotion* on the CNCF Landscape 🌍.

## ⚖️ Technical Oversight Committee (TOC)
The TOC helps guide the technical direction of CNCF projects. Its responsibilities include:

* 🧭 Defining the technical vision

* ✅ Approving new projects

* 🗣️ Accepting input from the End User Community

* 📐 Promoting consistent practices across CNCF projects

## 🧑‍🤝‍🧑 Community-Driven, Not Top-Down
Here’s what makes cloud native governance unique:

    Projects are self-governing and community-owned 👥

    CNCF uses a model of “minimum viable governance” — just enough structure to guide, but not control

    Rules around:

        📦 Releasing software

        👀 Code review processes

        👥 User and working group formation

In contrast to traditional, top-down corporate governance, cloud native projects thrive on voluntary participation, transparency, and shared ownership.

## 🛠️ Why Governance Matters
Strong, lightweight governance ensures:

* ⚖️ Fair decision-making

* 🚀 Sustainable project growth

* 🔄 Continuity even when contributors change

* 🔐 Trust from users and adopters

In open source, freedom comes with responsibility — contributors and maintainers agree to follow shared rules to keep the ecosystem healthy and inclusive 💡.
